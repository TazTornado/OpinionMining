{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Final Assignment\n",
    "### Sotiria Pantazi, 1115201700241"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from wordcloud import STOPWORDS\n",
    "from sklearn.feature_extraction import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/impermium_verification_set.csv')\n",
    "labeled_test = pd.read_csv('./data/impermium_verification_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Comment'] = train['Comment'].str.lower()\n",
    "test['Comment'] = test['Comment'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Applying on the train dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      Insult             Date  \\\n0          1  20120618192155Z   \n1          0  20120528192215Z   \n2          0              NaN   \n3          0              NaN   \n4          0  20120619094753Z   \n...      ...              ...   \n3942       1  20120502172717Z   \n3943       0  20120528164814Z   \n3944       0  20120620142813Z   \n3945       0  20120528205648Z   \n3946       0  20120515200734Z   \n\n                                                Comment  \n0                                    you fuck your dad   \n1      i really don t understand your point it seems...  \n2      a majority of canadians can and has been wron...  \n3      listen if you dont wanna get married to a man...  \n4      c c b n xu ng ng bi u t nh 2011 c n ho kh ng ...  \n...                                                 ...  \n3942   you are both morons and that is never happening   \n3943   many toolbars include spell check like yahoo ...  \n3944   lambeauorwrigley k moss sioux falls s d i tol...  \n3945   how about felix he is sure turning into one h...  \n3946   you re all upset defending this hipster band ...  \n\n[3947 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Insult</th>\n      <th>Date</th>\n      <th>Comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>20120618192155Z</td>\n      <td>you fuck your dad</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>20120528192215Z</td>\n      <td>i really don t understand your point it seems...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>a majority of canadians can and has been wron...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>listen if you dont wanna get married to a man...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>20120619094753Z</td>\n      <td>c c b n xu ng ng bi u t nh 2011 c n ho kh ng ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3942</th>\n      <td>1</td>\n      <td>20120502172717Z</td>\n      <td>you are both morons and that is never happening</td>\n    </tr>\n    <tr>\n      <th>3943</th>\n      <td>0</td>\n      <td>20120528164814Z</td>\n      <td>many toolbars include spell check like yahoo ...</td>\n    </tr>\n    <tr>\n      <th>3944</th>\n      <td>0</td>\n      <td>20120620142813Z</td>\n      <td>lambeauorwrigley k moss sioux falls s d i tol...</td>\n    </tr>\n    <tr>\n      <th>3945</th>\n      <td>0</td>\n      <td>20120528205648Z</td>\n      <td>how about felix he is sure turning into one h...</td>\n    </tr>\n    <tr>\n      <th>3946</th>\n      <td>0</td>\n      <td>20120515200734Z</td>\n      <td>you re all upset defending this hipster band ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3947 rows Ã— 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# source for this code: stackoverflow.com and medium.com\n",
    "train.Comment = train.Comment.apply(lambda x: re.sub(r'(\\\\x..)|(\\\\n)|(\\\\u....)', ' ', x))   # removing chars like \\n etc\n",
    "train.Comment = train.Comment.apply(lambda x: re.sub(r'(http/http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', x))    # removing urls\n",
    "train.Comment = train.Comment.apply(lambda x: re.sub(r'[^a-z0-9]+', ' ', x))    # removing any useless chars left\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Applying on the test dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        id  Insult             Date  \\\n0        1     NaN  20120603163526Z   \n1        2     NaN  20120531215447Z   \n2        3     NaN  20120823164228Z   \n3        4     NaN  20120826010752Z   \n4        5     NaN  20120602223825Z   \n...    ...     ...              ...   \n2230  2231     NaN  20120528100303Z   \n2231  2232     NaN  20120531185813Z   \n2232  2233     NaN  20120529130822Z   \n2233  2234     NaN  20120531045826Z   \n2234  2235     NaN  20120531184524Z   \n\n                                                Comment        Usage  \n0                                    you fuck your dad   PrivateTest  \n1      i really don t understand your point it seems...  PrivateTest  \n2      a majority of canadians can and has been wron...  PrivateTest  \n3      listen if you dont wanna get married to a man...  PrivateTest  \n4      c c b n xu ng ng bi u t nh 2011 c n ho kh ng ...  PrivateTest  \n...                                                 ...          ...  \n2230                                       you is shit   PrivateTest  \n2231   even if the bucks won the nba they wouldnt ca...  PrivateTest  \n2232   damn straight my friend if it s not the judge...  PrivateTest  \n2233   i d rather have an old straight white guy tha...  PrivateTest  \n2234   christopher m there are lots of animals in tr...  PrivateTest  \n\n[2235 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Insult</th>\n      <th>Date</th>\n      <th>Comment</th>\n      <th>Usage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>20120603163526Z</td>\n      <td>you fuck your dad</td>\n      <td>PrivateTest</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>20120531215447Z</td>\n      <td>i really don t understand your point it seems...</td>\n      <td>PrivateTest</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>20120823164228Z</td>\n      <td>a majority of canadians can and has been wron...</td>\n      <td>PrivateTest</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>20120826010752Z</td>\n      <td>listen if you dont wanna get married to a man...</td>\n      <td>PrivateTest</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>20120602223825Z</td>\n      <td>c c b n xu ng ng bi u t nh 2011 c n ho kh ng ...</td>\n      <td>PrivateTest</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2230</th>\n      <td>2231</td>\n      <td>NaN</td>\n      <td>20120528100303Z</td>\n      <td>you is shit</td>\n      <td>PrivateTest</td>\n    </tr>\n    <tr>\n      <th>2231</th>\n      <td>2232</td>\n      <td>NaN</td>\n      <td>20120531185813Z</td>\n      <td>even if the bucks won the nba they wouldnt ca...</td>\n      <td>PrivateTest</td>\n    </tr>\n    <tr>\n      <th>2232</th>\n      <td>2233</td>\n      <td>NaN</td>\n      <td>20120529130822Z</td>\n      <td>damn straight my friend if it s not the judge...</td>\n      <td>PrivateTest</td>\n    </tr>\n    <tr>\n      <th>2233</th>\n      <td>2234</td>\n      <td>NaN</td>\n      <td>20120531045826Z</td>\n      <td>i d rather have an old straight white guy tha...</td>\n      <td>PrivateTest</td>\n    </tr>\n    <tr>\n      <th>2234</th>\n      <td>2235</td>\n      <td>NaN</td>\n      <td>20120531184524Z</td>\n      <td>christopher m there are lots of animals in tr...</td>\n      <td>PrivateTest</td>\n    </tr>\n  </tbody>\n</table>\n<p>2235 rows Ã— 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# source for this code: stackoverflow.com and medium.com\n",
    "test.Comment = train.Comment.apply(lambda x: re.sub(r'(\\\\x..)|(\\\\n)|(\\\\u....)', ' ', x))   # removing chars like \\n etc\n",
    "test.Comment = train.Comment.apply(lambda x: re.sub(r'(http/http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', ' ', x))    # removing urls\n",
    "test.Comment = train.Comment.apply(lambda x: re.sub(r'[^a-z0-9]+', ' ', x))    # removing any useless chars left\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_metrics = ['f1', 'accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Using CountVectorizer - basic*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer() # initializing vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_train = vect.fit_transform(train.Comment.values)\n",
    "basic_train = basic_train.toarray()     # creating ndarray with features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_test = vect.transform(test.Comment.values)\n",
    "basic_test = basic_test.toarray()   # applying the same as above to the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GaussianNB(priors=None, var_smoothing=1e-09)"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "basicGNB = GaussianNB()\n",
    "basicGNB.fit(basic_train, train.Insult.values)    # y is the label (0 or 1) of insults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "F1 mean score: 0.37347561009810304\nAccuracy mean score: 0.5011010570147342\n"
    }
   ],
   "source": [
    "basic_scores = cross_validate(estimator = basicGNB, X = basic_test, y = labeled_test.Insult.values, scoring = validation_metrics, cv = 10, n_jobs = 6)\n",
    "print('F1 mean score:', basic_scores['test_f1'].mean())\n",
    "print('Accuracy mean score:', basic_scores['test_accuracy'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*With Lemmatization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lemmatizer(tweets):\n",
    "    tweetTok = TweetTokenizer()\n",
    "    wnlemm = WordNetLemmatizer()\n",
    "    tokenized = []\n",
    "    for t in tweets:\n",
    "        tokenized.append(tweetTok.tokenize(t))\n",
    "    lemmatized = []\n",
    "    for tok in tokenized:\n",
    "        lemm_i = []\n",
    "        for word in tok:\n",
    "            lemm_i.append(wnlemm.lemmatize(word))\n",
    "        lemm_i = ' '.join(lemm_i)\n",
    "        lemmatized.append(lemm_i)\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer() # initializing vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_train = Lemmatizer(train.Comment.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt1_train = vect.fit_transform(lemmatized_train)\n",
    "opt1_train = opt1_train.toarray()     # creating ndarray with features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_test = Lemmatizer(test.Comment.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt1_test = vect.transform(lemmatized_test)\n",
    "opt1_test = opt1_test.toarray()   # applying the same as above to the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GaussianNB(priors=None, var_smoothing=1e-09)"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "opt1GNB = GaussianNB()\n",
    "opt1GNB.fit(opt1_train, train.Insult.values)    # y is the label (0 or 1) of insults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "F1 mean score: 0.37110409764149693\nAccuracy mean score: 0.504234064702114\n"
    }
   ],
   "source": [
    "opt1_scores = cross_validate(estimator = opt1GNB, X = opt1_test, y = labeled_test.Insult.values, scoring = validation_metrics, cv = 10, n_jobs = 6)\n",
    "print('F1 mean score:', opt1_scores['test_f1'].mean())\n",
    "print('Accuracy mean score:', opt1_scores['test_accuracy'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*With Stopwords*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words = text.ENGLISH_STOP_WORDS) # initializing vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt2_train = vect.fit_transform(train.Comment.values)\n",
    "opt2_train = opt2_train.toarray()     # creating ndarray with features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt2_test = vect.transform(test.Comment.values)\n",
    "opt2_test = opt2_test.toarray()   # applying the same as above to the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GaussianNB(priors=None, var_smoothing=1e-09)"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "opt2GNB = GaussianNB()\n",
    "opt2GNB.fit(opt2_train, train.Insult.values)    # y is the label (0 or 1) of insults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "F1 mean score: 0.36869566998427594\nAccuracy mean score: 0.49797005124919924\n"
    }
   ],
   "source": [
    "opt2_scores = cross_validate(estimator = opt2GNB, X = opt2_test, y = labeled_test.Insult.values, scoring = validation_metrics, cv = 10, n_jobs = 6)\n",
    "print('F1 mean score:', opt2_scores['test_f1'].mean())\n",
    "print('Accuracy mean score:', opt2_scores['test_accuracy'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*With Bigrams*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range = (2,2)) # initializing vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt3_train = vect.fit_transform(train.Comment.values)\n",
    "opt3_train = opt3_train.toarray()     # creating ndarray with features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt3_test = vect.transform(test.Comment.values)\n",
    "opt3_test = opt3_test.toarray()   # applying the same as above to the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GaussianNB(priors=None, var_smoothing=1e-09)"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "opt3GNB = GaussianNB()\n",
    "opt3GNB.fit(opt3_train, train.Insult.values)    # y is the label (0 or 1) of insults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "F1 mean score: 0.4406924085305258\nAccuracy mean score: 0.5158872517616914\n"
    }
   ],
   "source": [
    "opt3_scores = cross_validate(estimator = opt3GNB, X = opt3_test, y = labeled_test.Insult.values, scoring = validation_metrics, cv = 10, n_jobs = 6)\n",
    "print('F1 mean score:', opt3_scores['test_f1'].mean())\n",
    "print('Accuracy mean score:', opt3_scores['test_accuracy'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*With Laplace Smoothing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer() # initializing vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "#MultinomialNB will be used since it provides the coefficient alpha for smoothing\n",
    "opt4MNB = MultinomialNB(alpha = 0.5)   # the basic alpha here will be 0.5\n",
    "opt4MNB.fit(basic_train, train.Insult.values)    # y is the label (0 or 1) of insults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "F1 mean score: 0.4521485869077558\nAccuracy mean score: 0.49664678090967324\n"
    }
   ],
   "source": [
    "opt4_scores = cross_validate(estimator = opt4MNB, X = basic_test, y = labeled_test.Insult.values, scoring = validation_metrics, cv = 10, n_jobs = 6)\n",
    "print('F1 mean score:', opt4_scores['test_f1'].mean())\n",
    "print('Accuracy mean score:', opt4_scores['test_accuracy'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Using TF-IDF and PoS*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Part-of-Speech based features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the source of this process's algorithm was found on stackoveflow.com\n",
    "def PoS_processing(tweets):  \n",
    "    tokzer = TweetTokenizer()\n",
    "    new_tweets = []\n",
    "    for tweet in tweets:\n",
    "        text = tokzer.tokenize(tweet)\n",
    "        tagged = nltk.pos_tag(text)\n",
    "        processed_tagged = []\n",
    "        for tag in tagged:\n",
    "            processed_tagged.append(tag[0] + \"/\" + tag[1])\n",
    "        new_tweets.append(' '.join(processed_tagged))\n",
    "    return new_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TF-IDF applied on extracted PoS features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_train = PoS_processing(train.Comment.values)\n",
    "pos_test = PoS_processing(test.Comment.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()   \n",
    "tf_train = tfidf.fit_transform(pos_train)\n",
    "tf_train = tf_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_test = tfidf.transform(pos_test)\n",
    "tf_test = tf_test.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GaussianNB(priors=None, var_smoothing=1e-09)"
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "source": [
    "comboGNB = GaussianNB()\n",
    "comboGNB.fit(tf_train, train.Insult.values)    # y is the label (0 or 1) of insults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "F1 mean score: 0.42276774672458506\nAccuracy mean score: 0.48990831197950035\n"
    }
   ],
   "source": [
    "combo_scores = cross_validate(estimator = comboGNB, X = tf_test, y = labeled_test.Insult.values, scoring = validation_metrics, cv = 10, n_jobs = 6)\n",
    "print('F1 mean score:', combo_scores['test_f1'].mean())\n",
    "print('Accuracy mean score:', combo_scores['test_accuracy'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method: Random Decision Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=16, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=4,\n                       oob_score=False, random_state=None, verbose=0,\n                       warm_start=False)"
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "forest = RandomForestClassifier(max_depth=16,n_jobs=4)\n",
    "forest.fit(tf_train, y = train.Insult.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "F1 mean score: 0.3158875539792419\nAccuracy mean score: 0.5123178251121077\n"
    }
   ],
   "source": [
    "forest_scores = cross_validate(estimator = forest, X = tf_test, y = labeled_test.Insult.values, scoring = validation_metrics, cv = 10, n_jobs = 6)\n",
    "print('F1 mean score:', forest_scores['test_f1'].mean())\n",
    "print('Accuracy mean score:', forest_scores['test_accuracy'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method: Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n    max_iter=-1, probability=False, random_state=None, shrinking=True,\n    tol=0.001, verbose=False)"
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "clf = SVC(kernel = 'rbf', C = 1)\n",
    "clf.fit(tf_train, y = train.Insult.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "F1 mean score: 0.37165013398480234\nAccuracy mean score: 0.482361066623959\n"
    }
   ],
   "source": [
    "svm_scores = cross_validate(estimator = clf, X = tf_test, y = labeled_test.Insult.values, scoring = validation_metrics, cv = 10, n_jobs = 6)\n",
    "print('F1 mean score:', svm_scores['test_f1'].mean())\n",
    "print('Accuracy mean score:', svm_scores['test_accuracy'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}